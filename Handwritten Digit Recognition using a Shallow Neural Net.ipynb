{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import MNISTtools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtrain, ltrain = MNISTtools.load(dataset='training', path = 'F:\\\\UCSD\\\\Quarter1\\\\ECE285\\\\Assignments\\\\Assignment1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 60000)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(ltrain.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "size of training dataset: 60000\n",
    "\n",
    "size of feature dimension: 784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFOEHkiL8QFKEH0iK8ANJ/QcTfYOLnk6g9wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1847382b390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "image42 = xtrain[:,42]\n",
    "image42_reshaped = np.reshape(image42, (28,28))\n",
    "pyplot.imshow(image42_reshaped, cmap='gray')\n",
    "pyplot.show()\n",
    "print(ltrain[42])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that the content corresponds to the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "255\n",
      "255\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minim = np.min(xtrain)\n",
    "maxim = np.max(xtrain)\n",
    "xtrain_range = maxim - minim\n",
    "print(minim)\n",
    "print(maxim)\n",
    "print(xtrain_range)\n",
    "xtrain.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_MNIST_images(x):\n",
    "    y = x.astype(np.float32)\n",
    "    divisor = 255/2\n",
    "    y_new_range = (y/divisor)-1\n",
    "    return y_new_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0\n",
      "1.0\n",
      "2.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dtype('float32')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xtrain = normalize_MNIST_images(xtrain)\n",
    "minim = np.min(xtrain)\n",
    "maxim = np.max(xtrain)\n",
    "xtrain_newrange_range = maxim - minim\n",
    "print(minim)\n",
    "print(maxim)\n",
    "print(xtrain_newrange_range)\n",
    "xtrain.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def label2onehot(lbl):\n",
    "    d = np.zeros((lbl.max() + 1, lbl.size))\n",
    "    d[lbl, np.arange(lbl.size)] = 1\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      "(10, 60000)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(ltrain[42])\n",
    "dtrain = label2onehot(ltrain)\n",
    "print(dtrain[:,42])\n",
    "print(dtrain.shape)\n",
    "print(ltrain.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def onehot2label(d):\n",
    "    lbl = d.argmax(axis=0)\n",
    "    return lbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5 0 4 ..., 5 6 8]\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "x = onehot2label(dtrain)\n",
    "print(x)\n",
    "print(x[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmax(a):\n",
    "    a_max = np.zeros((1,60000))\n",
    "    a_max = a.max(axis = 0)\n",
    "    a_sane = a - a_max\n",
    "    a_sane_exp = np.exp(a_sane)\n",
    "    y = a_sane_exp/(a_sane_exp.sum(axis = 0))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softmaxp(a,e):\n",
    "    k = softmax(a)\n",
    "    part1 = np.multiply(k,e)\n",
    "    new = part1.sum(axis = 0)\n",
    "    part2 = np.multiply(new.T,k)\n",
    "    return(part1 - part2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if softmax and softmaxp work correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.11569689137e-07 should be smaller than 1e-6\n"
     ]
    }
   ],
   "source": [
    "eps = 1e-6 # finite difference step\n",
    "a = np.random.randn(10, 200) # random inputs\n",
    "e = np.random.randn(10, 200) # random directions\n",
    "diff = softmaxp(a, e)\n",
    "diff_approx = (softmax(a + (eps*e)) - softmax(a))/eps\n",
    "rel_error = np.abs(diff - diff_approx).mean() / np.abs(diff_approx).mean()\n",
    "print(rel_error, 'should be smaller than 1e-6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing ReLU and ReLUp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(a):\n",
    "    return(np.where(a>0,a,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relup(a,e):\n",
    "#    for i in range(a.shape[0]):\n",
    "#        for j in range(a.shape[1]):\n",
    "#            if a[i][j]>0:\n",
    "#                a[i][j] = 1\n",
    "#            else:\n",
    "#                a[i][j] = 0 \n",
    "#    a[a>0]=1\n",
    "    a = np.where(a>0,1,0)\n",
    "    return(a*e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking if relu and relup work correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.33952738812e-10 should be smaller than 1e-6\n"
     ]
    }
   ],
   "source": [
    "eps = 1e-6 # finite difference step\n",
    "a = np.random.randn(10, 200) # random inputs\n",
    "e = np.random.randn(10, 200) # random directions\n",
    "diff2 = relup(a, e)\n",
    "#print(diff)\n",
    "diff_approx2 = (relu(a + (eps*e)) - relu(a))/eps\n",
    "#print(diff_approx)\n",
    "rel_error2 = (np.abs(diff2 - diff_approx2)).mean() / np.abs(diff_approx).mean()\n",
    "print(rel_error2, 'should be smaller than 1e-6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing Shallow Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def init_shallow(Ni, Nh, No):\n",
    "    b1 = np.random.randn(Nh, 1) / np.sqrt((Ni+1.)/2.)\n",
    "    W1 = np.random.randn(Nh, Ni) / np.sqrt((Ni+1.)/2.)\n",
    "    b2 = np.random.randn(No, 1) / np.sqrt((Nh+1.))\n",
    "    W2 = np.random.randn(No, Nh) / np.sqrt((Nh+1.))\n",
    "    return W1, b1, W2, b2\n",
    "Ni = xtrain.shape[0]\n",
    "Nh = 64\n",
    "No = dtrain.shape[0]\n",
    "netinit = init_shallow(Ni, Nh, No)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forwardprop_shallow(x, net):\n",
    "    W1 = net[0]\n",
    "    b1 = net[1]\n",
    "    W2 = net[2]\n",
    "    b2 = net[3]\n",
    "    Z1 = W1.dot(x) + b1\n",
    "    a1 = relu(Z1)\n",
    "    a2 = W2.dot(a1) + b2\n",
    "    y = softmax(a2)\n",
    "    return y\n",
    "yinit = forwardprop_shallow(xtrain, netinit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.95753902803 should be around .26\n"
     ]
    }
   ],
   "source": [
    "def eval_loss(y, d):\n",
    "    sum_vert = -np.log(y)*d\n",
    "    return(sum_vert.sum()/y.shape[1])\n",
    "print(eval_loss(yinit, dtrain), 'should be around .26')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.3283333333\n"
     ]
    }
   ],
   "source": [
    "def eval_perfs(y, lbl):\n",
    "    y_oneD = onehot2label(y)\n",
    "    perf_par = (y_oneD != lbl)\n",
    "    sum_perf_par = perf_par.sum()\n",
    "    return (sum_perf_par/lbl.shape[0])*100\n",
    "print(eval_perfs(yinit, ltrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_shallow(x, d, net, gamma=.05):\n",
    "    W1 = net[0]\n",
    "    b1 = net[1]\n",
    "    W2 = net[2]\n",
    "    b2 = net[3]\n",
    "    Ni = W1.shape[1]\n",
    "    Nh = W1.shape[0]\n",
    "    No = W2.shape[0]\n",
    "    gamma = gamma / x.shape[1] # normalized by the training dataset size\n",
    "    Z1 = W1.dot(x) + b1\n",
    "    a1 = relu(Z1)\n",
    "    a2 = W2.dot(a1) + b2\n",
    "    y = softmax(a2)\n",
    "    e2 = - d / y\n",
    "    delta2 = softmaxp(a2,e2)\n",
    "    e1 = W2.T.dot(delta2)\n",
    "    delta1 = relup(a1, e1) \n",
    "    W2 = W2 - gamma * delta2.dot(a1.T)\n",
    "    W1 = W1 - gamma * delta1.dot(x.T)\n",
    "    b2 = b2 - gamma * delta2.sum(axis =1, keepdims = True )\n",
    "    b1 = b1 - gamma * delta1.sum(axis =1, keepdims = True )\n",
    "    return W1, b1, W2, b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backprop_shallow(x, d, net, T, gamma=.05):\n",
    "    lbl = onehot2label(d)\n",
    "    for t in range(T):\n",
    "        net = update_shallow(x, d, net)\n",
    "        #net = [W1,b1,W2,b2]\n",
    "        y = forwardprop_shallow(x, net)\n",
    "        loss = eval_loss(y, d)\n",
    "        print(loss)\n",
    "        performance = eval_perfs(y, lbl)\n",
    "        print(performance)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.51097931787\n",
      "88.1716666667\n",
      "2.26106138433\n",
      "84.14\n",
      "2.13687675119\n",
      "78.2733333333\n",
      "2.03757017369\n",
      "72.5966666667\n",
      "1.95209051349\n",
      "67.2516666667\n",
      "1.87278327946\n",
      "61.37\n",
      "1.80371494753\n",
      "59.2366666667\n",
      "1.73954684901\n",
      "53.5166666667\n",
      "1.69275255909\n",
      "54.9183333333\n",
      "1.64887365985\n",
      "50.0283333333\n",
      "1.64453456806\n",
      "53.96\n",
      "1.60946652714\n",
      "47.975\n",
      "1.60114327013\n",
      "52.3333333333\n",
      "1.53341269248\n",
      "43.955\n",
      "1.47533974855\n",
      "47.6016666667\n",
      "1.41589532622\n",
      "39.4583333333\n",
      "1.35308947861\n",
      "41.9533333333\n",
      "1.3046211098\n",
      "35.6116666667\n",
      "1.24906149621\n",
      "37.0466666667\n",
      "1.21225368507\n",
      "32.7216666667\n",
      "1.16371780423\n",
      "33.2916666667\n",
      "1.13889145035\n",
      "30.8516666667\n",
      "1.0943674923\n",
      "30.5166666667\n",
      "1.07956902607\n",
      "29.515\n",
      "1.03751277\n",
      "28.5183333333\n",
      "1.02935357453\n",
      "28.63\n",
      "0.989338797323\n",
      "26.9716666667\n",
      "0.984790746541\n",
      "27.82\n",
      "0.947039503819\n",
      "25.7083333333\n",
      "0.944181906989\n",
      "26.985\n",
      "0.908869030794\n",
      "24.5816666667\n",
      "0.906756450304\n",
      "26.1783333333\n",
      "0.873873118249\n",
      "23.6616666667\n",
      "0.872045053721\n",
      "25.3166666667\n",
      "0.841527649205\n",
      "22.7883333333\n",
      "0.839885308179\n",
      "24.475\n",
      "0.81173036966\n",
      "22.0183333333\n",
      "0.810240922035\n",
      "23.5116666667\n",
      "0.784592519781\n",
      "21.35\n",
      "0.783391770026\n",
      "22.73\n",
      "0.759859619859\n",
      "20.7016666667\n",
      "0.758831243072\n",
      "21.9766666667\n",
      "0.737306995901\n",
      "20.1566666667\n",
      "0.736374027749\n",
      "21.2316666667\n",
      "0.716786669531\n",
      "19.6716666667\n",
      "0.715826695735\n",
      "20.5966666667\n",
      "0.697942861445\n",
      "19.2033333333\n",
      "0.696858504383\n",
      "19.935\n",
      "0.680603240132\n",
      "18.7733333333\n",
      "0.679339171459\n",
      "19.355\n",
      "0.664592406274\n",
      "18.4183333333\n",
      "0.663147028142\n",
      "18.7633333333\n",
      "0.649781973584\n",
      "18.0516666667\n",
      "0.648166293923\n",
      "18.2216666667\n",
      "0.636050074929\n",
      "17.6983333333\n",
      "0.634218600782\n",
      "17.775\n",
      "0.623287932536\n",
      "17.3783333333\n",
      "0.621284849667\n",
      "17.335\n",
      "0.611392740867\n",
      "17.065\n",
      "0.609247390413\n",
      "16.9816666667\n",
      "0.60026790626\n",
      "16.7316666667\n",
      "0.597962555525\n",
      "16.6583333333\n",
      "0.589816919205\n",
      "16.435\n",
      "0.587408931446\n",
      "16.3183333333\n",
      "0.580011257771\n",
      "16.1683333333\n",
      "0.577510717561\n",
      "16.005\n",
      "0.570792030178\n",
      "15.9333333333\n",
      "0.568226155259\n",
      "15.6766666667\n",
      "0.56212143941\n",
      "15.685\n",
      "0.559510450072\n",
      "15.3883333333\n",
      "0.553937609663\n",
      "15.4616666667\n",
      "0.551287784452\n",
      "15.165\n",
      "0.546196572687\n",
      "15.2166666667\n",
      "0.543534946317\n",
      "14.935\n",
      "0.538859232573\n",
      "14.9983333333\n",
      "0.536211148385\n",
      "14.6983333333\n",
      "0.531903524344\n",
      "14.79\n",
      "0.529285338012\n",
      "14.495\n",
      "0.525320375439\n",
      "14.5866666667\n",
      "0.522731970569\n",
      "14.315\n",
      "0.519057118568\n",
      "14.405\n",
      "0.516516114036\n",
      "14.1533333333\n",
      "0.513105257692\n",
      "14.225\n",
      "0.510610298838\n",
      "13.9783333333\n",
      "0.507449289207\n",
      "14.05\n",
      "0.505017012455\n",
      "13.83\n",
      "0.502067580577\n",
      "13.9\n",
      "0.499706676549\n",
      "13.68\n",
      "0.496949414992\n",
      "13.7566666667\n",
      "0.494663666694\n",
      "13.565\n",
      "0.492072702923\n",
      "13.6383333333\n",
      "0.489863471229\n",
      "13.4466666667\n",
      "0.487432996986\n",
      "13.5266666667\n",
      "0.485300695427\n",
      "13.295\n",
      "0.483015110554\n",
      "13.4316666667\n",
      "0.480957616949\n",
      "13.1916666667\n",
      "0.478799144784\n",
      "13.2866666667\n",
      "0.476819385138\n",
      "13.105\n",
      "0.474774788408\n",
      "13.205\n",
      "0.472868019396\n",
      "13.0266666667\n"
     ]
    }
   ],
   "source": [
    "nettrain_batch = backprop_shallow(xtrain, dtrain, netinit, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xtest, ltest = MNISTtools.load(dataset='testing', path = 'F:\\\\UCSD\\\\Quarter1\\\\ECE285\\\\Assignments\\\\Assignment1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 10000)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(xtest.shape)\n",
    "print(ltest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.07\n"
     ]
    }
   ],
   "source": [
    "xtest = normalize_MNIST_images(xtest)\n",
    "dtest = label2onehot(ltest)\n",
    "ytest = forwardprop_shallow(xtest, nettrain_batch)\n",
    "perf = eval_perfs(ytest, ltest)\n",
    "print(perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Mini Batch Gradient Descent on the same data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backprop_minibatch_shallow(x, d, net, T, B=100, gamma=.05):\n",
    "    N = x.shape[1]\n",
    "    NB = int((N+B-1)/B)\n",
    "    lbl = onehot2label(d)\n",
    "    for t in range(T):\n",
    "        shuffled_indices = np.random.permutation(range(N))\n",
    "        for l in range(NB):\n",
    "            minibatch_indices = shuffled_indices[B*l:min(B*(l+1), N)]\n",
    "            #COMPLETE TO UPDATE NET\n",
    "            net = update_shallow(x[:,shuffled_indices], d[:,shuffled_indices], net)\n",
    "        y = forwardprop_shallow(x, net);\n",
    "        #COMPLETE TO DISPLAY LOSS AND PERFS\n",
    "        loss = eval_loss(y, d);\n",
    "        print(loss)\n",
    "        perf = eval_perfs(y, lbl);\n",
    "        print(perf)\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.282351495798\n",
      "8.07833333333\n",
      "0.222290940262\n",
      "6.23833333333\n",
      "0.184813342844\n",
      "5.23333333333\n",
      "0.158335527491\n",
      "4.44\n",
      "0.138874640026\n",
      "3.87\n"
     ]
    }
   ],
   "source": [
    "nettrain = backprop_minibatch_shallow(xtrain, dtrain, netinit, 5, B=100, gamma=.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the performance of Mini Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.24\n"
     ]
    }
   ],
   "source": [
    "ytest = forwardprop_shallow(xtest, nettrain)\n",
    "perf = eval_perfs(ytest, ltest)\n",
    "print(perf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that Mini Batch Gradient Descent performs much better than Batch Gradient Descent."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
